{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "import talib\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "class FeatureBase(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all features.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def compute(self, data=None, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Abstract method to compute the feature value for the given data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# TODO: there's some wrong in calculate trend ways, add a new method that can split data by date\n",
    "class IndicatorTrend(FeatureBase):\n",
    "    \"\"\"\n",
    "    Indicator to calculate the trend based on various methods.\n",
    "    \"\"\"\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the trend for the given data using the specified method.\n",
    "\n",
    "        Parameters:\n",
    "        - data: DataFrame containing the data.\n",
    "        - method: Method for trend calculation (e.g., 'MA', 'LocalExtrema').\n",
    "        - ma_days: Number of days for moving average.\n",
    "        - oder_days: Number of days for order.\n",
    "        - trend_days: Number of days to determine the trend.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame with trend values.\n",
    "        \"\"\"\n",
    "        method = kwargs.get('method', 'MA')\n",
    "        ma_days = kwargs.get('ma_days', 20)\n",
    "        oder_days = kwargs.get('oder_days', 20)\n",
    "        trend_days = kwargs.get('trend_days', 5)\n",
    "\n",
    "        if method == 'MA':\n",
    "            return self.calculate_trend_MA(data, ma_days=ma_days, trend_days=trend_days)\n",
    "        elif method == 'LocalExtrema':\n",
    "            return self.calculate_trend_LocalExtrema(data, oder_days=oder_days)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid trend calculation method: {method}\")\n",
    "\n",
    "    def calculate_trend_MA(self, data, ma_days=20, trend_days=5):\n",
    "        \"\"\"\n",
    "        Calculate trend using Moving Average method.\n",
    "\n",
    "        Parameters:\n",
    "        - data: DataFrame containing the data.\n",
    "        - ma_days: Number of days for moving average.\n",
    "        - trend_days: Number of days to determine the trend.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame with trend values.\n",
    "        \"\"\"\n",
    "        data['MA'] = data['Close'].rolling(window=ma_days).mean()\n",
    "        data['Trend'] = np.nan\n",
    "        n = len(data)\n",
    "\n",
    "        for i in range(n - trend_days + 1):\n",
    "            if all(data['MA'].iloc[i + j] < data['MA'].iloc[i + j + 1] for j in range(trend_days - 1)):\n",
    "                data['Trend'].iloc[i:i + trend_days] = 0\n",
    "            elif all(data['MA'].iloc[i + j] > data['MA'].iloc[i + j + 1] for j in range(trend_days - 1)):\n",
    "                data['Trend'].iloc[i:i + trend_days] = 1\n",
    "        data['Trend'].fillna(method='ffill', inplace=True)\n",
    "        return data.drop(columns=['MA'])\n",
    "\n",
    "    def calculate_trend_LocalExtrema(self, data, oder_days=20):\n",
    "        \"\"\"\n",
    "        Calculate trend using Local Extrema method.\n",
    "\n",
    "        Parameters:\n",
    "        - data: DataFrame containing the data.\n",
    "        - oder_days: Number of days for order.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame with trend values.\n",
    "        \"\"\"\n",
    "        local_max_indices = argrelextrema(\n",
    "            data['Close'].values, np.greater_equal, order=oder_days)[0]\n",
    "        local_min_indices = argrelextrema(\n",
    "            data['Close'].values, np.less_equal, order=oder_days)[0]\n",
    "        data['Local Max'] = data.iloc[local_max_indices]['Close']\n",
    "        data['Local Min'] = data.iloc[local_min_indices]['Close']\n",
    "        data['Trend'] = np.nan\n",
    "        prev_idx = None\n",
    "        prev_trend = None\n",
    "        prev_type = None\n",
    "\n",
    "        for idx in sorted(np.concatenate([local_max_indices, local_min_indices])):\n",
    "            if idx in local_max_indices:\n",
    "                current_type = \"max\"\n",
    "            else:\n",
    "                current_type = \"min\"\n",
    "\n",
    "            if prev_trend is None:\n",
    "                if current_type == \"max\":\n",
    "                    prev_trend = 1\n",
    "                else:\n",
    "                    prev_trend = 0\n",
    "            else:\n",
    "                if prev_type == \"max\" and current_type == \"min\":\n",
    "                    data.loc[prev_idx:idx, 'Trend'] = 1\n",
    "                    prev_trend = 1\n",
    "                elif prev_type == \"min\" and current_type == \"max\":\n",
    "                    data.loc[prev_idx:idx, 'Trend'] = 0\n",
    "                    prev_trend = 0\n",
    "                else:\n",
    "                    if current_type == \"max\":\n",
    "                        data.loc[prev_idx:idx, 'Trend'] = 0\n",
    "                        prev_trend = 0\n",
    "                    else:\n",
    "                        data.loc[prev_idx:idx, 'Trend'] = 1\n",
    "                        prev_trend = 1\n",
    "\n",
    "            prev_idx = idx\n",
    "            prev_type = current_type\n",
    "        data['Trend'].fillna(method='ffill', inplace=True)\n",
    "        return data.drop(columns=['Local Max', 'Local Min'])\n",
    "\n",
    "\n",
    "class IndicatorMACD(FeatureBase):\n",
    "    \"\"\"\n",
    "    Indicator to calculate the Moving Average Convergence Divergence (MACD).\n",
    "    \"\"\"\n",
    "\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        fastperiod = kwargs.get('fastperiod', 5)\n",
    "        slowperiod = kwargs.get('slowperiod', 10)\n",
    "        signalperiod = kwargs.get('signalperiod', 9)\n",
    "        data['MACD'], _, _ = talib.MACD(\n",
    "            data['Close'], fastperiod=fastperiod, slowperiod=slowperiod, signalperiod=signalperiod)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorROC(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        trend_days = kwargs.get('trend_days', 5)\n",
    "        data['ROC'] = talib.ROC(data['Close'], timeperiod=trend_days)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorStochasticOscillator(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        trend_days = kwargs.get('trend_days', 5)\n",
    "        data['StoK'], data['StoD'] = talib.STOCH(\n",
    "            data['High'], data['Low'], data['Close'], fastk_period=trend_days, slowk_period=3, slowd_period=3)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorCCI(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        timeperiod = kwargs.get('timeperiod', 14)\n",
    "        data['CCI'] = talib.CCI(data['High'], data['Low'],\n",
    "                                data['Close'], timeperiod=timeperiod)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorRSI(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        timeperiod = kwargs.get('timeperiod', 14)\n",
    "        data['RSI'] = talib.RSI(data['Close'], timeperiod=timeperiod)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorVMA(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        timeperiod = kwargs.get('timeperiod', 20)\n",
    "        data['VMA'] = talib.MA(data['Volume'], timeperiod=timeperiod)\n",
    "        return data\n",
    "\n",
    "\n",
    "class IndicatorPctChange(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        data['pctChange'] = data['Close'].pct_change() * 100\n",
    "        return data\n",
    "\n",
    "\n",
    "class TreasuryYieldThreeMonth(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        start_date = kwargs.get('start_date')\n",
    "        end_date = kwargs.get('end_date')\n",
    "        three_month_treasury_yield = yf.download(\n",
    "            \"^IRX\", start_date, end_date)[\"Close\"]\n",
    "        data['3M Treasury Yield'] = three_month_treasury_yield\n",
    "        return data\n",
    "\n",
    "\n",
    "class TreasuryYieldFiveYear(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        start_date = kwargs.get('start_date')\n",
    "        end_date = kwargs.get('end_date')\n",
    "        five_year_treasury_yield = yf.download(\n",
    "            \"^FVX\", start_date, end_date)[\"Close\"]\n",
    "        data['5Y Treasury Yield'] = five_year_treasury_yield\n",
    "        return data\n",
    "\n",
    "\n",
    "class TreasuryYieldTenYear(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        start_date = kwargs.get('start_date')\n",
    "        end_date = kwargs.get('end_date')\n",
    "        ten_year_treasury_yield = yf.download(\n",
    "            \"^TNX\", start_date, end_date)[\"Close\"]\n",
    "        data['10Y Treasury Yield'] = ten_year_treasury_yield\n",
    "        return data\n",
    "\n",
    "\n",
    "class TreasuryYieldThirtyYear(FeatureBase):\n",
    "    def compute(self, data, *args, **kwargs):\n",
    "        start_date = kwargs.get('start_date')\n",
    "        end_date = kwargs.get('end_date')\n",
    "        thirty_year_treasury_yield = yf.download(\n",
    "            \"^TYX\", start_date, end_date)[\"Close\"]\n",
    "        data['30Y Treasury Yield'] = thirty_year_treasury_yield\n",
    "        return data\n",
    "# Add other features here as needed\n",
    "\n",
    "\n",
    "class FeatureFactory:\n",
    "    \"\"\"\n",
    "    Factory class dedicated to creating various technical features.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def get_feature(feature_type):\n",
    "        \"\"\"\n",
    "        Retrieve the desired feature based on the specified type.\n",
    "\n",
    "        Parameters:\n",
    "        - feature_type: Type of feature (e.g., 'Trend', 'MACD').\n",
    "\n",
    "        Returns:\n",
    "        - Feaature object corresponding to the specified type.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If the provided feature type is not supported.\n",
    "        \"\"\"\n",
    "        features = {\n",
    "            \"Trend\": IndicatorTrend,\n",
    "            \"MACD\": IndicatorMACD,\n",
    "            \"ROC\": IndicatorROC,\n",
    "            \"Stochastic Oscillator\": IndicatorStochasticOscillator,\n",
    "            \"CCI\": IndicatorCCI,\n",
    "            \"RSI\": IndicatorRSI,\n",
    "            \"VMA\": IndicatorVMA,\n",
    "            \"PctChange\": IndicatorPctChange,\n",
    "            \"3M Treasury Yield\": TreasuryYieldThreeMonth,\n",
    "            \"5Y Treasury Yield\": TreasuryYieldFiveYear,\n",
    "            \"10Y Treasury Yield\": TreasuryYieldTenYear,\n",
    "            \"30Y Treasury Yield\": TreasuryYieldThirtyYear,\n",
    "            # Add other features here as needed\n",
    "        }\n",
    "        feature = features.get(feature_type)\n",
    "        if feature is None:\n",
    "            raise ValueError(f\"Invalid feature type: {feature_type}\")\n",
    "        return feature()\n",
    "\n",
    "\n",
    "class CleanerBase(ABC):\n",
    "    \"\"\"Abstract base class for data processors.\"\"\"\n",
    "    @abstractmethod\n",
    "    def check(self, data):\n",
    "        \"\"\"Method to check the data for issues.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def clean(self, data):\n",
    "        \"\"\"Method to clean the data from identified issues.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class CleanerMissingValue(CleanerBase):\n",
    "    \"\"\"Concrete class for checking and handling missing data.\"\"\"\n",
    "    def check(self, data):\n",
    "        \"\"\"Check for missing data in the dataframe.\"\"\"\n",
    "        return data.isnull().sum()\n",
    "\n",
    "    def clean(self, data, strategy='auto'):\n",
    "        \"\"\"Handle missing data based on the chosen strategy.\"\"\"\n",
    "        if strategy == 'auto':\n",
    "            while data.iloc[0].isnull().any():\n",
    "                data = data.iloc[1:]\n",
    "            data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        elif strategy == 'drop':\n",
    "            data.dropna(inplace=True)\n",
    "\n",
    "        elif strategy == 'fillna':\n",
    "            data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        elif strategy == 'none':\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy provided.\")\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class ProcessorFactory:\n",
    "    \"\"\"Factory class to create data processors.\"\"\"\n",
    "    @staticmethod\n",
    "    def get_cleaner(clean_type, *args, **kwargs):\n",
    "        \"\"\"Create a data processor based on the provided type.\"\"\"\n",
    "        if clean_type == \"MissingData\":\n",
    "            return CleanerMissingValue(*args, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Processor type {clean_type} not recognized.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_standardize_method(data, method='StandardScaler'):\n",
    "        \"\"\"Standardize the data using the specified method.\"\"\"\n",
    "        if method == 'StandardScaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif method == 'MinMaxScaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid scaler method: {method}.\")\n",
    "        return scaler.fit_transform(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_and_split_data(data, split_ratio=0.7, target_col=\"Trend\", feature_cols=None):\n",
    "        \"\"\"Standardize the data and split it into training and testing sets.\"\"\"\n",
    "        if not feature_cols:\n",
    "            feature_cols = data.columns.to_list()\n",
    "        x_data = data[feature_cols]\n",
    "\n",
    "        # Generate the one-hot encoding\n",
    "        y_data = pd.get_dummies(data[target_col], prefix='Trend')\n",
    "\n",
    "        # Check if the split index is valid\n",
    "        split_idx = int(len(x_data) * split_ratio)\n",
    "        if split_idx < 1 or split_idx >= len(x_data):\n",
    "            raise ValueError(\n",
    "                \"Invalid split ratio leading to incorrect data partitioning.\")\n",
    "\n",
    "        X_test = x_data.iloc[split_idx:]\n",
    "        y_test = y_data.iloc[split_idx:]\n",
    "        X_train = x_data.iloc[:split_idx]\n",
    "        y_train = y_data.iloc[:split_idx]\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_multistep_data(x_data, y_data, look_back, predict_steps, slide_steps=1):\n",
    "        \"\"\"\n",
    "        Prepare the data for multi-step prediction and apply standardization within each sliding window.\n",
    "        \"\"\"\n",
    "        x_date = []\n",
    "        y_date = []\n",
    "        x_data_multistep = []\n",
    "        y_data_multistep = []\n",
    "\n",
    "        for i in range(0, len(x_data) - look_back - predict_steps + 1, slide_steps):\n",
    "            x_date.append(x_data.index[i:i + look_back])\n",
    "\n",
    "            y_date.append(\n",
    "                x_data.index[i + look_back:i + look_back + predict_steps])\n",
    "\n",
    "            x_window = x_data.iloc[i:i + look_back].values\n",
    "            y_window = y_data.iloc[i + look_back:i +\n",
    "                                   look_back + predict_steps].values\n",
    "\n",
    "            x_window_standardized = ProcessorFactory.get_standardize_method(\n",
    "                x_window)\n",
    "\n",
    "            x_data_multistep.append(x_window_standardized)\n",
    "            y_data_multistep.append(y_window)\n",
    "\n",
    "        return np.array(x_data_multistep), np.array(y_data_multistep), np.array(x_date), np.array(y_date)\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"\n",
    "    Fetching, processing, and preparing model data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data=None, start_date=None, end_date=None):\n",
    "        self.data = data\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.trend_method = \"MA\"\n",
    "        self.features = []\n",
    "        self.processors = []\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def set_seed(self, seed_value=42):\n",
    "        \"\"\"Set seed for reproducibility.\"\"\"\n",
    "        np.random.seed(seed_value)\n",
    "\n",
    "    def fetch_stock_data(self, stock_symbol, start_date=None, end_date=None):\n",
    "        \"\"\"Fetch stock data from Yahoo Finance.\"\"\"\n",
    "        if start_date:\n",
    "            self.start_date = start_date\n",
    "        if end_date:\n",
    "            self.end_date = end_date\n",
    "        return yf.download(stock_symbol, start=self.start_date, end=self.end_date)\n",
    "\n",
    "    def add_feature(self, feature_type, *args, **kwargs):\n",
    "        feature = FeatureFactory.get_feature(feature_type)\n",
    "        self.data = feature.compute(self.data, *args, **kwargs)\n",
    "\n",
    "    def add_data_cleaner(self, clean_type='MissingData', strategy='drop'):\n",
    "        \"\"\"Method to check and clean the data using a specific processor.\"\"\"\n",
    "        processor = ProcessorFactory.get_cleaner(clean_type)\n",
    "        issues = processor.check(self.data)\n",
    "        self.data = processor.clean(self.data, strategy=strategy)\n",
    "        return issues\n",
    "\n",
    "    def process_data(self, split_ratio=0.7, target_col=\"Trend\", feature_cols=None, look_back=64, predict_steps=16, train_slide_steps=1, test_slide_steps=16):\n",
    "        \"\"\"\n",
    "        Use ProcessorFactory to standardize and split the data, and prepare it for multi-step prediction if required.\n",
    "        \"\"\"\n",
    "        self.X_train, self.y_train, self.X_test, self.y_test = ProcessorFactory.standardize_and_split_data(\n",
    "            self.data, split_ratio, target_col, feature_cols)\n",
    "\n",
    "        if look_back and predict_steps:\n",
    "            self.X_train, self.y_train, self.train_dates, _ = ProcessorFactory.prepare_multistep_data(\n",
    "                self.X_train, self.y_train, look_back, predict_steps, train_slide_steps)\n",
    "            self.X_test, self.y_test, _, self.test_dates = ProcessorFactory.prepare_multistep_data(\n",
    "                self.X_test, self.y_test, look_back, predict_steps, test_slide_steps)\n",
    "\n",
    "\n",
    "model_data = Preprocessor()\n",
    "model_data.set_seed(42)\n",
    "start_date = \"2001-01-01\"\n",
    "stop_date = \"2021-01-01\"\n",
    "stock_symbol = \"^GSPC\"\n",
    "model_data.data = model_data.fetch_stock_data(\n",
    "    stock_symbol, start_date, stop_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>1320.280029</td>\n",
       "      <td>1320.280029</td>\n",
       "      <td>1276.050049</td>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1129400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1347.760010</td>\n",
       "      <td>1274.619995</td>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1880700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1350.239990</td>\n",
       "      <td>1329.140015</td>\n",
       "      <td>1333.339966</td>\n",
       "      <td>1333.339966</td>\n",
       "      <td>2131000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>1333.339966</td>\n",
       "      <td>1334.770020</td>\n",
       "      <td>1294.949951</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1430800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1276.290039</td>\n",
       "      <td>1295.859985</td>\n",
       "      <td>1295.859985</td>\n",
       "      <td>1115500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>3694.030029</td>\n",
       "      <td>3703.820068</td>\n",
       "      <td>3689.320068</td>\n",
       "      <td>3703.060059</td>\n",
       "      <td>3703.060059</td>\n",
       "      <td>1883780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>3723.030029</td>\n",
       "      <td>3740.510010</td>\n",
       "      <td>3723.030029</td>\n",
       "      <td>3735.360107</td>\n",
       "      <td>3735.360107</td>\n",
       "      <td>3535460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>3750.010010</td>\n",
       "      <td>3756.120117</td>\n",
       "      <td>3723.310059</td>\n",
       "      <td>3727.040039</td>\n",
       "      <td>3727.040039</td>\n",
       "      <td>3393290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>3736.189941</td>\n",
       "      <td>3744.629883</td>\n",
       "      <td>3730.209961</td>\n",
       "      <td>3732.040039</td>\n",
       "      <td>3732.040039</td>\n",
       "      <td>3154850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>3733.270020</td>\n",
       "      <td>3760.199951</td>\n",
       "      <td>3726.879883</td>\n",
       "      <td>3756.070068</td>\n",
       "      <td>3756.070068</td>\n",
       "      <td>3179040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5032 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2001-01-02  1320.280029  1320.280029  1276.050049  1283.270020  1283.270020   \n",
       "2001-01-03  1283.270020  1347.760010  1274.619995  1347.560059  1347.560059   \n",
       "2001-01-04  1347.560059  1350.239990  1329.140015  1333.339966  1333.339966   \n",
       "2001-01-05  1333.339966  1334.770020  1294.949951  1298.349976  1298.349976   \n",
       "2001-01-08  1298.349976  1298.349976  1276.290039  1295.859985  1295.859985   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2020-12-24  3694.030029  3703.820068  3689.320068  3703.060059  3703.060059   \n",
       "2020-12-28  3723.030029  3740.510010  3723.030029  3735.360107  3735.360107   \n",
       "2020-12-29  3750.010010  3756.120117  3723.310059  3727.040039  3727.040039   \n",
       "2020-12-30  3736.189941  3744.629883  3730.209961  3732.040039  3732.040039   \n",
       "2020-12-31  3733.270020  3760.199951  3726.879883  3756.070068  3756.070068   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2001-01-02  1129400000  \n",
       "2001-01-03  1880700000  \n",
       "2001-01-04  2131000000  \n",
       "2001-01-05  1430800000  \n",
       "2001-01-08  1115500000  \n",
       "...                ...  \n",
       "2020-12-24  1883780000  \n",
       "2020-12-28  3535460000  \n",
       "2020-12-29  3393290000  \n",
       "2020-12-30  3154850000  \n",
       "2020-12-31  3179040000  \n",
       "\n",
       "[5032 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e4903\\AppData\\Local\\Temp\\ipykernel_18264\\46640999.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Trend'].iloc[i:i + trend_days] = 0\n",
      "C:\\Users\\e4903\\AppData\\Local\\Temp\\ipykernel_18264\\46640999.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Trend'].iloc[i:i + trend_days] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    {\"type\": \"Trend\", \"method\": \"MA\", \"oder_days\": 20,\n",
    "        \"ma_days\": 20, \"trend_days\": 5},\n",
    "    {\"type\": \"MACD\", \"fastperiod\": 5, \"slowperiod\": 10, \"signalperiod\": 9},\n",
    "    {\"type\": \"ROC\", \"trend_days\": 5},\n",
    "    {\"type\": \"Stochastic Oscillator\", \"trend_days\": 5},\n",
    "    {\"type\": \"CCI\", \"timeperiod\": 14},\n",
    "    {\"type\": \"RSI\", \"timeperiod\": 14},\n",
    "    {\"type\": \"VMA\", \"timeperiod\": 20},\n",
    "    {\"type\": \"PctChange\"},\n",
    "    {\"type\": \"3M Treasury Yield\", \"start_date\": \"2001-01-01\", \"end_date\": \"2021-01-01\"},\n",
    "    {\"type\": \"5Y Treasury Yield\", \"start_date\": \"2001-01-01\", \"end_date\": \"2021-01-01\"},\n",
    "    {\"type\": \"10Y Treasury Yield\", \"start_date\": \"2001-01-01\", \"end_date\": \"2021-01-01\"},\n",
    "    {\"type\": \"30Y Treasury Yield\", \"start_date\": \"2001-01-01\", \"end_date\": \"2021-01-01\"},\n",
    "]  # Add other features here as needed\n",
    "\n",
    "for feature_params in features:\n",
    "    feature_type = feature_params[\"type\"]\n",
    "    model_data.add_feature(feature_type, **feature_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Trend</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>StoK</th>\n",
       "      <th>StoD</th>\n",
       "      <th>CCI</th>\n",
       "      <th>RSI</th>\n",
       "      <th>VMA</th>\n",
       "      <th>pctChange</th>\n",
       "      <th>3M Treasury Yield</th>\n",
       "      <th>5Y Treasury Yield</th>\n",
       "      <th>10Y Treasury Yield</th>\n",
       "      <th>30Y Treasury Yield</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>1320.280029</td>\n",
       "      <td>1320.280029</td>\n",
       "      <td>1276.050049</td>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1129400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680</td>\n",
       "      <td>4.752</td>\n",
       "      <td>4.917</td>\n",
       "      <td>5.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>1283.270020</td>\n",
       "      <td>1347.760010</td>\n",
       "      <td>1274.619995</td>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1880700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.009861</td>\n",
       "      <td>5.530</td>\n",
       "      <td>4.923</td>\n",
       "      <td>5.097</td>\n",
       "      <td>5.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>1347.560059</td>\n",
       "      <td>1350.239990</td>\n",
       "      <td>1329.140015</td>\n",
       "      <td>1333.339966</td>\n",
       "      <td>1333.339966</td>\n",
       "      <td>2131000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.055247</td>\n",
       "      <td>5.240</td>\n",
       "      <td>4.808</td>\n",
       "      <td>5.013</td>\n",
       "      <td>5.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>1333.339966</td>\n",
       "      <td>1334.770020</td>\n",
       "      <td>1294.949951</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1430800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.624236</td>\n",
       "      <td>4.970</td>\n",
       "      <td>4.672</td>\n",
       "      <td>4.948</td>\n",
       "      <td>5.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1298.349976</td>\n",
       "      <td>1276.290039</td>\n",
       "      <td>1295.859985</td>\n",
       "      <td>1295.859985</td>\n",
       "      <td>1115500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.191781</td>\n",
       "      <td>5.050</td>\n",
       "      <td>4.601</td>\n",
       "      <td>4.897</td>\n",
       "      <td>5.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>3694.030029</td>\n",
       "      <td>3703.820068</td>\n",
       "      <td>3689.320068</td>\n",
       "      <td>3703.060059</td>\n",
       "      <td>3703.060059</td>\n",
       "      <td>1883780000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.338616</td>\n",
       "      <td>-0.521693</td>\n",
       "      <td>63.138326</td>\n",
       "      <td>63.276036</td>\n",
       "      <td>54.766231</td>\n",
       "      <td>61.278661</td>\n",
       "      <td>4.609992e+09</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>3723.030029</td>\n",
       "      <td>3740.510010</td>\n",
       "      <td>3723.030029</td>\n",
       "      <td>3735.360107</td>\n",
       "      <td>3735.360107</td>\n",
       "      <td>3535460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.249831</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>76.059963</td>\n",
       "      <td>66.443033</td>\n",
       "      <td>165.892897</td>\n",
       "      <td>65.834224</td>\n",
       "      <td>4.647846e+09</td>\n",
       "      <td>0.872253</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>3750.010010</td>\n",
       "      <td>3756.120117</td>\n",
       "      <td>3723.310059</td>\n",
       "      <td>3727.040039</td>\n",
       "      <td>3727.040039</td>\n",
       "      <td>3393290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.046858</td>\n",
       "      <td>0.869305</td>\n",
       "      <td>77.492969</td>\n",
       "      <td>72.230419</td>\n",
       "      <td>141.836511</td>\n",
       "      <td>63.753548</td>\n",
       "      <td>4.502090e+09</td>\n",
       "      <td>-0.222738</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>3736.189941</td>\n",
       "      <td>3744.629883</td>\n",
       "      <td>3730.209961</td>\n",
       "      <td>3732.040039</td>\n",
       "      <td>3732.040039</td>\n",
       "      <td>3154850000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.569669</td>\n",
       "      <td>1.214453</td>\n",
       "      <td>74.218337</td>\n",
       "      <td>75.923756</td>\n",
       "      <td>119.256437</td>\n",
       "      <td>64.480076</td>\n",
       "      <td>4.388908e+09</td>\n",
       "      <td>0.134155</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>3733.270020</td>\n",
       "      <td>3760.199951</td>\n",
       "      <td>3726.879883</td>\n",
       "      <td>3756.070068</td>\n",
       "      <td>3756.070068</td>\n",
       "      <td>3179040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.794560</td>\n",
       "      <td>1.790241</td>\n",
       "      <td>73.926272</td>\n",
       "      <td>75.212526</td>\n",
       "      <td>129.781854</td>\n",
       "      <td>67.818646</td>\n",
       "      <td>4.295798e+09</td>\n",
       "      <td>0.643885</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5032 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2001-01-02  1320.280029  1320.280029  1276.050049  1283.270020  1283.270020   \n",
       "2001-01-03  1283.270020  1347.760010  1274.619995  1347.560059  1347.560059   \n",
       "2001-01-04  1347.560059  1350.239990  1329.140015  1333.339966  1333.339966   \n",
       "2001-01-05  1333.339966  1334.770020  1294.949951  1298.349976  1298.349976   \n",
       "2001-01-08  1298.349976  1298.349976  1276.290039  1295.859985  1295.859985   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2020-12-24  3694.030029  3703.820068  3689.320068  3703.060059  3703.060059   \n",
       "2020-12-28  3723.030029  3740.510010  3723.030029  3735.360107  3735.360107   \n",
       "2020-12-29  3750.010010  3756.120117  3723.310059  3727.040039  3727.040039   \n",
       "2020-12-30  3736.189941  3744.629883  3730.209961  3732.040039  3732.040039   \n",
       "2020-12-31  3733.270020  3760.199951  3726.879883  3756.070068  3756.070068   \n",
       "\n",
       "                Volume  Trend       MACD       ROC       StoK       StoD  \\\n",
       "Date                                                                       \n",
       "2001-01-02  1129400000    NaN        NaN       NaN        NaN        NaN   \n",
       "2001-01-03  1880700000    NaN        NaN       NaN        NaN        NaN   \n",
       "2001-01-04  2131000000    NaN        NaN       NaN        NaN        NaN   \n",
       "2001-01-05  1430800000    NaN        NaN       NaN        NaN        NaN   \n",
       "2001-01-08  1115500000    NaN        NaN       NaN        NaN        NaN   \n",
       "...                ...    ...        ...       ...        ...        ...   \n",
       "2020-12-24  1883780000    0.0   5.338616 -0.521693  63.138326  63.276036   \n",
       "2020-12-28  3535460000    0.0  10.249831  0.699577  76.059963  66.443033   \n",
       "2020-12-29  3393290000    0.0  11.046858  0.869305  77.492969  72.230419   \n",
       "2020-12-30  3154850000    0.0  11.569669  1.214453  74.218337  75.923756   \n",
       "2020-12-31  3179040000    0.0  14.794560  1.790241  73.926272  75.212526   \n",
       "\n",
       "                   CCI        RSI           VMA  pctChange  3M Treasury Yield  \\\n",
       "Date                                                                            \n",
       "2001-01-02         NaN        NaN           NaN        NaN              5.680   \n",
       "2001-01-03         NaN        NaN           NaN   5.009861              5.530   \n",
       "2001-01-04         NaN        NaN           NaN  -1.055247              5.240   \n",
       "2001-01-05         NaN        NaN           NaN  -2.624236              4.970   \n",
       "2001-01-08         NaN        NaN           NaN  -0.191781              5.050   \n",
       "...                ...        ...           ...        ...                ...   \n",
       "2020-12-24   54.766231  61.278661  4.609992e+09   0.353659              0.075   \n",
       "2020-12-28  165.892897  65.834224  4.647846e+09   0.872253              0.080   \n",
       "2020-12-29  141.836511  63.753548  4.502090e+09  -0.222738              0.090   \n",
       "2020-12-30  119.256437  64.480076  4.388908e+09   0.134155              0.070   \n",
       "2020-12-31  129.781854  67.818646  4.295798e+09   0.643885              0.065   \n",
       "\n",
       "            5Y Treasury Yield  10Y Treasury Yield  30Y Treasury Yield  \n",
       "Date                                                                   \n",
       "2001-01-02              4.752               4.917               5.350  \n",
       "2001-01-03              4.923               5.097               5.463  \n",
       "2001-01-04              4.808               5.013               5.435  \n",
       "2001-01-05              4.672               4.948               5.414  \n",
       "2001-01-08              4.601               4.897               5.408  \n",
       "...                       ...                 ...                 ...  \n",
       "2020-12-24              0.364               0.928               1.664  \n",
       "2020-12-28              0.364               0.933               1.669  \n",
       "2020-12-29              0.378               0.935               1.674  \n",
       "2020-12-30              0.370               0.926               1.662  \n",
       "2020-12-31              0.361               0.917               1.646  \n",
       "\n",
       "[5032 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open                   0\n",
       "High                   0\n",
       "Low                    0\n",
       "Close                  0\n",
       "Adj Close              0\n",
       "Volume                 0\n",
       "Trend                 19\n",
       "MACD                  17\n",
       "ROC                    5\n",
       "StoK                   8\n",
       "StoD                   8\n",
       "CCI                   13\n",
       "RSI                   14\n",
       "VMA                   19\n",
       "pctChange              1\n",
       "3M Treasury Yield      7\n",
       "5Y Treasury Yield      7\n",
       "10Y Treasury Yield     7\n",
       "30Y Treasury Yield     7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_detected = model_data.add_data_cleaner(\"MissingData\", strategy='auto')\n",
    "issues_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open                  0\n",
       "High                  0\n",
       "Low                   0\n",
       "Close                 0\n",
       "Adj Close             0\n",
       "Volume                0\n",
       "Trend                 0\n",
       "MACD                  0\n",
       "ROC                   0\n",
       "StoK                  0\n",
       "StoD                  0\n",
       "CCI                   0\n",
       "RSI                   0\n",
       "VMA                   0\n",
       "pctChange             0\n",
       "3M Treasury Yield     0\n",
       "5Y Treasury Yield     0\n",
       "10Y Treasury Yield    0\n",
       "30Y Treasury Yield    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3430, 64, 19), (3430, 16, 2), (90, 64, 19), (90, 16, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.7\n",
    "target_col = \"Trend\"\n",
    "feature_cols = None  # None means use all columns\n",
    "# feature_cols = ['Close']\n",
    "look_back = 64  # number of previous days' data to consider\n",
    "predict_steps = 16  # number of days to predict in the future\n",
    "slide_steps = 1  # sliding window step size\n",
    "\n",
    "model_data.process_data(split_ratio=0.7, target_col=\"Trend\", feature_cols=feature_cols, look_back=look_back,\n",
    "                        predict_steps=predict_steps, train_slide_steps=1, test_slide_steps=predict_steps)\n",
    "\n",
    "model_data.X_train.shape, model_data.y_train.shape, model_data.X_test.shape, model_data.y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trend_0': 3252, 'Trend_1': 1761}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the last dimension and calculating the ratio of the two classes in model_data.y_train\n",
    "class_0_count = np.sum(model_data.data['Trend'] == 0)\n",
    "class_1_count = np.sum(model_data.data['Trend'] == 1)\n",
    "\n",
    "class_ratio = {\n",
    "    \"Trend_0\": class_0_count,\n",
    "    \"Trend_1\": class_1_count\n",
    "}\n",
    "\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trend_0': 34900, 'Trend_1': 19980}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the last dimension and calculating the ratio of the two classes in model_data.y_train\n",
    "class_0_count = np.sum(model_data.y_train[:, :, 0])\n",
    "class_1_count = np.sum(model_data.y_train[:, :, 1])\n",
    "\n",
    "class_ratio = {\n",
    "    \"Trend_0\": class_0_count,\n",
    "    \"Trend_1\": class_1_count\n",
    "}\n",
    "\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trend_0': 1008, 'Trend_1': 432}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the last dimension and calculating the ratio of the two classes in model_data.y_train\n",
    "class_0_count = np.sum(model_data.y_test[:, :, 0])\n",
    "class_1_count = np.sum(model_data.y_test[:, :, 1])\n",
    "\n",
    "class_ratio = {\n",
    "    \"Trend_0\": class_0_count,\n",
    "    \"Trend_1\": class_1_count\n",
    "}\n",
    "\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unittest\n",
    "\n",
    "\n",
    "# class TestData(unittest.TestCase):\n",
    "\n",
    "#     def setUp(self):\n",
    "#         self.model_data = Preprocessor()\n",
    "#         self.model_data.set_seed(42)\n",
    "#         self.start_date = \"2020-01-01\"\n",
    "#         self.end_date = \"2021-01-01\"\n",
    "#         self.stock_symbol = \"^GSPC\"\n",
    "\n",
    "#         # Mock data for the tests to avoid yfinance dependency\n",
    "#         x = np.linspace(0, 50, 1000)  # Generate 1000 points between 0 and 50\n",
    "#         sin_wave = np.sin(x)  # Generate a sinusoidal wave\n",
    "#         self.model_data.data = pd.DataFrame({\n",
    "#             'Open': sin_wave,\n",
    "#             'High': sin_wave + 0.1,  # Adding a small value to simulate the 'High' value for the day\n",
    "#             # Subtracting a small value to simulate the 'Low' value for the day\n",
    "#             'Low': sin_wave - 0.1,\n",
    "#             'Close': sin_wave,\n",
    "#             'Trend': [0 for i in range(1000)]\n",
    "#             # 'Trend': [(i % 2) for i in range(1000)]\n",
    "#         })\n",
    "\n",
    "#     def test_fetch_stock_data(self):\n",
    "#         self.assertIsNotNone(self.model_data.data)\n",
    "#         self.assertFalse(self.model_data.data.empty)\n",
    "\n",
    "#     def test_add_single_indicator(self):\n",
    "#         initial_columns = set(self.model_data.data.columns)\n",
    "#         self.model_data.add_indicator(\"MACD\", fastperiod=5,\n",
    "#                                       slowperiod=10, signalperiod=9)\n",
    "#         new_columns = set(self.model_data.data.columns)\n",
    "#         self.assertGreater(len(new_columns), len(initial_columns))\n",
    "\n",
    "#     def test_add_multiple_indicators(self):\n",
    "#         initial_columns = set(self.model_data.data.columns)\n",
    "#         self.model_data.add_indicator(\"RSI\", timeperiod=14)\n",
    "#         self.model_data.add_indicator(\"CCI\", timeperiod=14)\n",
    "#         new_columns = set(self.model_data.data.columns)\n",
    "#         self.assertGreater(len(new_columns), len(initial_columns))\n",
    "\n",
    "#     def test_invalid_indicator(self):\n",
    "#         with self.assertRaises(ValueError):\n",
    "#             self.model_data.add_indicator(\"InvalidIndicatorName\")\n",
    "\n",
    "#     def test_data_cleaning(self):\n",
    "#         # Introducing missing values into the mock data\n",
    "#         self.model_data.data.iloc[2, 1] = np.nan\n",
    "#         self.model_data.data.iloc[4, 3] = np.nan\n",
    "#         initial_missing_count = self.model_data.data.isnull().sum().sum()\n",
    "\n",
    "#         # Use the add_data_cleaner method to clean the data\n",
    "#         self.model_data.add_data_cleaner(\"MissingData\", strategy='auto')\n",
    "\n",
    "#         # Verify that missing values have been cleaned\n",
    "#         final_missing_count = self.model_data.data.isnull().sum().sum()\n",
    "#         self.assertLess(final_missing_count, initial_missing_count)\n",
    "\n",
    "#     def test_data_splitting(self):\n",
    "#         # Populate the mock data with necessary features\n",
    "#         features = [\n",
    "#             {\"type\": \"Trend\", \"method\": \"MA\", \"oder_days\": 20,\n",
    "#                 \"ma_days\": 20, \"trend_days\": 5},\n",
    "#             # Add other necessary features here\n",
    "#         ]\n",
    "\n",
    "#         for indicator_params in features:\n",
    "#             feature_type = indicator_params[\"type\"]\n",
    "#             self.model_data.add_indicator(feature_type, **indicator_params)\n",
    "\n",
    "#         # Call the process_data method to standardize and split the data\n",
    "#         split_ratio = 0.7\n",
    "#         target_col = \"Trend\"\n",
    "#         feature_cols = None\n",
    "#         look_back = 10\n",
    "#         predict_steps = 5\n",
    "#         slide_steps = 1\n",
    "\n",
    "#         self.model_data.process_data(split_ratio=split_ratio, target_col=target_col,\n",
    "#                                      look_back=look_back, predict_steps=predict_steps, slide_steps=slide_steps)\n",
    "\n",
    "#         # Test the shape of the training and testing datasets\n",
    "#         self.assertEqual(\n",
    "#             self.model_data.X_train.shape[0], self.model_data.y_train.shape[0])\n",
    "#         self.assertEqual(\n",
    "#             self.model_data.X_test.shape[0], self.model_data.y_test.shape[0])\n",
    "\n",
    "#         # Ensure sum of lengths of train and test datasets matches the length of the original dataset\n",
    "#         total_data_points = len(self.model_data.data) - \\\n",
    "#             look_back - predict_steps + 1\n",
    "#         self.assertEqual(\n",
    "#             self.model_data.X_train.shape[0] + self.model_data.X_test.shape[0], total_data_points)\n",
    "\n",
    "#         # Ensure data split ratio is approximately maintained\n",
    "#         train_ratio = self.model_data.X_train.shape[0] / total_data_points\n",
    "#         self.assertAlmostEqual(train_ratio, split_ratio, places=1)\n",
    "\n",
    "\n",
    "# # Running the tests\n",
    "# unittest_result_splitting = unittest.TextTestRunner().run(\n",
    "#     unittest.TestLoader().loadTestsFromTestCase(TestData))\n",
    "# unittest_result_splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
